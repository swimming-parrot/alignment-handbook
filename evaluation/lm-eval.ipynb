{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-27:10:32:20,658 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:32:20,659 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:32:26,227 WARNING  [__main__.py:221]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2024-02-27:10:32:26,227 INFO     [__main__.py:226] Including path: ./configs\n",
      "2024-02-27:10:32:26,227 INFO     [__init__.py:349] To still use tasks loaded from args.include_path,see an example of the new TaskManager API in https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-27:10:32:26,228 INFO     [__main__.py:285] Selected Tasks: ['demo_boolq']\n",
      "2024-02-27:10:32:26,228 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:32:26,228 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:32:26,229 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:32:26,229 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:32:26,309 INFO     [huggingface.py:161] Using device 'cuda'\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 288, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 123, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/api/model.py\", line 134, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 233, in __init__\n",
      "    self._create_tokenizer(\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 591, in _create_tokenizer\n",
      "    self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 737, in from_pretrained\n",
      "    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py\", line 569, in get_tokenizer_config\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/hub.py\", line 389, in cached_file\n",
      "    resolved_file = hf_hub_download(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1238, in hf_hub_download\n",
      "    metadata = get_hf_file_metadata(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1631, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 385, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 408, in _request_wrapper\n",
      "    response = get_session().request(method=method, url=url, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/huggingface_hub/utils/_http.py\", line 67, in send\n",
      "    return super().send(request, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 790, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/urllib3/connection.py\", line 461, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/http/client.py\", line 1386, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/http/client.py\", line 325, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/http/client.py\", line 286, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/ssl.py\", line 1315, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-2.8b \\\n",
    "    --include_path ./configs \\\n",
    "    --tasks demo_boolq \\\n",
    "    --limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-27:06:45:34,064 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:06:45:34,064 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:06:45:40,019 INFO     [__main__.py:285] Selected Tasks: ['hellaswag']\n",
      "2024-02-27:06:45:40,019 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:06:45:40,019 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:06:45:40,019 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:06:45:40,019 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:06:45:40,439 INFO     [huggingface.py:161] Using device 'cuda:4'\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:06:45:43,742 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-27:06:46:53,464 INFO     [task.py:361] Building contexts for hellaswag on rank 0...\n",
      "2024-02-27:06:46:59,889 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "100%|████████████████████████████████████| 40168/40168 [00:48<00:00, 832.28it/s]\n",
      "hf (pretrained=EleutherAI/pythia-70m), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n",
      "|  Tasks  |Version|Filter|n-shot| Metric |Value|   |Stderr|\n",
      "|---------|------:|------|------|--------|----:|---|-----:|\n",
      "|hellaswag|      1|none  |None  |acc     | 0.25|±  |0.0043|\n",
      "|         |       |none  |None  |acc_norm| 0.25|±  |0.0043|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks hellaswag \\\n",
    "    --device cuda:4 \\\n",
    "    --batch_size 8 \\\n",
    "    --num_fewshot 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARC-Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 8, in <module>\n",
      "    import torch\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/__init__.py\", line 1854, in <module>\n",
      "    from . import _meta_registrations\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 6242, in <module>\n",
      "    activate_meta()\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 6239, in activate_meta\n",
      "    _meta_lib_dont_use_me_use_register_meta.impl(op_overload, fn)\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/library.py\", line 168, in impl\n",
      "    self.m.impl(name, dispatch_key if dispatch_key != \"\" else \"CompositeImplicitAutograd\", fn)\n",
      "  File \"<frozen importlib._bootstrap>\", line 216, in _lock_unlock_module\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks arc_challenge \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HellaSwag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-27:06:50:48,517 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:06:50:48,517 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:06:50:54,007 INFO     [__main__.py:285] Selected Tasks: ['hellaswag']\n",
      "2024-02-27:06:50:54,008 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:06:50:54,008 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:06:50:54,008 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:06:50:54,009 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:06:50:54,051 INFO     [huggingface.py:161] Using device 'cuda:4'\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:06:50:56,942 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-27:06:51:07,842 WARNING  [evaluator.py:182] Overwriting default num_fewshot of hellaswag from None to 10\n",
      "2024-02-27:06:51:07,848 INFO     [task.py:361] Building contexts for hellaswag on rank 0...\n",
      "2024-02-27:06:54:51,359 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "100%|████████████████████████████████████| 40168/40168 [02:37<00:00, 255.19it/s]\n",
      "hf (pretrained=EleutherAI/pythia-70m), gen_kwargs: (None), limit: None, num_fewshot: 10, batch_size: 8\n",
      "|  Tasks  |Version|Filter|n-shot| Metric |Value |   |Stderr|\n",
      "|---------|------:|------|-----:|--------|-----:|---|-----:|\n",
      "|hellaswag|      1|none  |    10|acc     |0.2504|±  |0.0043|\n",
      "|         |       |none  |    10|acc_norm|0.2504|±  |0.0043|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks hellaswag \\\n",
    "    --device cuda:4 \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained='TinyLlama/pythia-1.4b' \\\n",
    "    --tasks hellaswag \\\n",
    "    # --device cuda:4 \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-27:10:22:58,193 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:22:58,193 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:22:58,654 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:22:58,654 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:22:58,708 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:22:58,708 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:22:58,732 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:22:58,732 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:23:03,775 INFO     [__main__.py:285] Selected Tasks: ['mmlu']\n",
      "2024-02-27:10:23:03,776 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:23:03,776 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:23:03,776 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:23:03,776 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:23:04,110 INFO     [__main__.py:285] Selected Tasks: ['mmlu']\n",
      "2024-02-27:10:23:04,110 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:23:04,111 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:23:04,111 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:23:04,111 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:23:04,346 INFO     [__main__.py:285] Selected Tasks: ['mmlu']\n",
      "2024-02-27:10:23:04,346 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:23:04,346 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:23:04,346 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:23:04,346 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:23:04,732 INFO     [__main__.py:285] Selected Tasks: ['mmlu']\n",
      "2024-02-27:10:23:04,733 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:23:04,733 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:23:04,733 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:23:04,733 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "[2024-02-27 10:23:05,407] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-27 10:23:05,901] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:23:06,128 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "[2024-02-27 10:23:06,312] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-27 10:23:06,467] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:23:06,639 INFO     [huggingface.py:322] Using 4 devices with data parallelism\n",
      "2024-02-27:10:23:06,639 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:23:07,005 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:23:07,181 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
      "2024-02-27:10:25:33,069 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_management from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
      "2024-02-27:10:25:33,070 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
      "2024-02-27:10:25:33,071 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
      "2024-02-27:10:25:33,073 INFO     [task.py:361] Building contexts for mmlu_moral_disputes on rank 2...\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
      "2024-02-27:10:25:35,582 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_management from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
      "2024-02-27:10:25:35,583 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
      "2024-02-27:10:25:35,584 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
      "2024-02-27:10:25:35,585 INFO     [task.py:361] Building contexts for mmlu_moral_disputes on rank 3...\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
      "2024-02-27:10:25:38,737 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_management from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
      "2024-02-27:10:25:38,738 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
      "2024-02-27:10:25:38,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
      "2024-02-27:10:25:38,740 INFO     [task.py:361] Building contexts for mmlu_moral_disputes on rank 1...\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_disputes from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_world_religions from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_prehistory from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_philosophy from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_international_law from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5\n",
      "2024-02-27:10:25:43,002 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_law from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_formal_logic from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_jurisprudence from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_psychology from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_sexuality from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_public_relations from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_security_studies from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_econometrics from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_geography from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_sociology from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_management from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_virology from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_medicine from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_accounting from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_business_ethics from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_marketing from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_nutrition from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_global_facts from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_miscellaneous from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_human_aging from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_professional_medicine from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_medical_genetics from None to 5\n",
      "2024-02-27:10:25:43,003 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_physics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_computer_security from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_biology from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_astronomy from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_biology from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_chemistry from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_machine_learning from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_mathematics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_high_school_physics from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_anatomy from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_college_computer_science from None to 5\n",
      "2024-02-27:10:25:43,004 WARNING  [evaluator.py:182] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5\n",
      "2024-02-27:10:25:43,005 INFO     [task.py:361] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "2024-02-27:10:25:45,351 INFO     [task.py:361] Building contexts for mmlu_world_religions on rank 3...\n",
      "2024-02-27:10:25:45,355 INFO     [task.py:361] Building contexts for mmlu_world_religions on rank 0...\n",
      "2024-02-27:10:25:45,360 INFO     [task.py:361] Building contexts for mmlu_world_religions on rank 2...\n",
      "2024-02-27:10:25:45,364 INFO     [task.py:361] Building contexts for mmlu_world_religions on rank 1...\n",
      "2024-02-27:10:25:46,224 INFO     [task.py:361] Building contexts for mmlu_moral_scenarios on rank 1...\n",
      "2024-02-27:10:25:46,225 INFO     [task.py:361] Building contexts for mmlu_moral_scenarios on rank 3...\n",
      "2024-02-27:10:25:46,225 INFO     [task.py:361] Building contexts for mmlu_moral_scenarios on rank 2...\n",
      "2024-02-27:10:25:46,225 INFO     [task.py:361] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "2024-02-27:10:25:50,646 INFO     [task.py:361] Building contexts for mmlu_prehistory on rank 3...\n",
      "2024-02-27:10:25:50,646 INFO     [task.py:361] Building contexts for mmlu_prehistory on rank 1...\n",
      "2024-02-27:10:25:50,646 INFO     [task.py:361] Building contexts for mmlu_prehistory on rank 2...\n",
      "2024-02-27:10:25:50,647 INFO     [task.py:361] Building contexts for mmlu_prehistory on rank 0...\n",
      "2024-02-27:10:25:52,260 INFO     [task.py:361] Building contexts for mmlu_philosophy on rank 0...\n",
      "2024-02-27:10:25:52,260 INFO     [task.py:361] Building contexts for mmlu_philosophy on rank 2...\n",
      "2024-02-27:10:25:52,260 INFO     [task.py:361] Building contexts for mmlu_philosophy on rank 3...\n",
      "2024-02-27:10:25:52,260 INFO     [task.py:361] Building contexts for mmlu_philosophy on rank 1...\n",
      "2024-02-27:10:25:53,809 INFO     [task.py:361] Building contexts for mmlu_logical_fallacies on rank 3...\n",
      "2024-02-27:10:25:53,809 INFO     [task.py:361] Building contexts for mmlu_logical_fallacies on rank 1...\n",
      "2024-02-27:10:25:53,809 INFO     [task.py:361] Building contexts for mmlu_logical_fallacies on rank 2...\n",
      "2024-02-27:10:25:53,809 INFO     [task.py:361] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "2024-02-27:10:25:54,625 INFO     [task.py:361] Building contexts for mmlu_high_school_european_history on rank 3...\n",
      "2024-02-27:10:25:54,625 INFO     [task.py:361] Building contexts for mmlu_high_school_european_history on rank 2...\n",
      "2024-02-27:10:25:54,625 INFO     [task.py:361] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "2024-02-27:10:25:54,625 INFO     [task.py:361] Building contexts for mmlu_high_school_european_history on rank 1...\n",
      "2024-02-27:10:25:55,445 INFO     [task.py:361] Building contexts for mmlu_international_law on rank 1...\n",
      "2024-02-27:10:25:55,445 INFO     [task.py:361] Building contexts for mmlu_international_law on rank 3...\n",
      "2024-02-27:10:25:55,445 INFO     [task.py:361] Building contexts for mmlu_international_law on rank 0...\n",
      "2024-02-27:10:25:55,445 INFO     [task.py:361] Building contexts for mmlu_international_law on rank 2...\n",
      "2024-02-27:10:25:56,045 INFO     [task.py:361] Building contexts for mmlu_high_school_us_history on rank 3...\n",
      "2024-02-27:10:25:56,045 INFO     [task.py:361] Building contexts for mmlu_high_school_us_history on rank 2...\n",
      "2024-02-27:10:25:56,045 INFO     [task.py:361] Building contexts for mmlu_high_school_us_history on rank 1...\n",
      "2024-02-27:10:25:56,046 INFO     [task.py:361] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "2024-02-27:10:25:57,070 INFO     [task.py:361] Building contexts for mmlu_professional_law on rank 3...\n",
      "2024-02-27:10:25:57,070 INFO     [task.py:361] Building contexts for mmlu_professional_law on rank 2...\n",
      "2024-02-27:10:25:57,070 INFO     [task.py:361] Building contexts for mmlu_professional_law on rank 1...\n",
      "2024-02-27:10:25:57,070 INFO     [task.py:361] Building contexts for mmlu_professional_law on rank 0...\n",
      "2024-02-27:10:26:04,677 INFO     [task.py:361] Building contexts for mmlu_formal_logic on rank 3...\n",
      "2024-02-27:10:26:04,677 INFO     [task.py:361] Building contexts for mmlu_formal_logic on rank 1...\n",
      "2024-02-27:10:26:04,677 INFO     [task.py:361] Building contexts for mmlu_formal_logic on rank 2...\n",
      "2024-02-27:10:26:04,678 INFO     [task.py:361] Building contexts for mmlu_formal_logic on rank 0...\n",
      "2024-02-27:10:26:05,315 INFO     [task.py:361] Building contexts for mmlu_jurisprudence on rank 3...\n",
      "2024-02-27:10:26:05,315 INFO     [task.py:361] Building contexts for mmlu_jurisprudence on rank 1...\n",
      "2024-02-27:10:26:05,315 INFO     [task.py:361] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "2024-02-27:10:26:05,315 INFO     [task.py:361] Building contexts for mmlu_jurisprudence on rank 2...\n",
      "2024-02-27:10:26:05,850 INFO     [task.py:361] Building contexts for mmlu_high_school_world_history on rank 3...\n",
      "2024-02-27:10:26:05,850 INFO     [task.py:361] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "2024-02-27:10:26:05,850 INFO     [task.py:361] Building contexts for mmlu_high_school_world_history on rank 1...\n",
      "2024-02-27:10:26:05,851 INFO     [task.py:361] Building contexts for mmlu_high_school_world_history on rank 2...\n",
      "2024-02-27:10:26:07,020 INFO     [task.py:361] Building contexts for mmlu_professional_psychology on rank 1...\n",
      "2024-02-27:10:26:07,022 INFO     [task.py:361] Building contexts for mmlu_professional_psychology on rank 3...\n",
      "2024-02-27:10:26:07,022 INFO     [task.py:361] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "2024-02-27:10:26:07,022 INFO     [task.py:361] Building contexts for mmlu_professional_psychology on rank 2...\n",
      "2024-02-27:10:26:09,913 INFO     [task.py:361] Building contexts for mmlu_us_foreign_policy on rank 1...\n",
      "2024-02-27:10:26:09,913 INFO     [task.py:361] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "2024-02-27:10:26:09,913 INFO     [task.py:361] Building contexts for mmlu_us_foreign_policy on rank 3...\n",
      "2024-02-27:10:26:09,914 INFO     [task.py:361] Building contexts for mmlu_us_foreign_policy on rank 2...\n",
      "2024-02-27:10:26:10,344 INFO     [task.py:361] Building contexts for mmlu_human_sexuality on rank 3...\n",
      "2024-02-27:10:26:10,344 INFO     [task.py:361] Building contexts for mmlu_human_sexuality on rank 1...\n",
      "2024-02-27:10:26:10,344 INFO     [task.py:361] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "2024-02-27:10:26:10,344 INFO     [task.py:361] Building contexts for mmlu_human_sexuality on rank 2...\n",
      "2024-02-27:10:26:10,912 INFO     [task.py:361] Building contexts for mmlu_public_relations on rank 3...\n",
      "2024-02-27:10:26:10,912 INFO     [task.py:361] Building contexts for mmlu_public_relations on rank 2...\n",
      "2024-02-27:10:26:10,912 INFO     [task.py:361] Building contexts for mmlu_public_relations on rank 0...\n",
      "2024-02-27:10:26:10,912 INFO     [task.py:361] Building contexts for mmlu_public_relations on rank 1...\n",
      "2024-02-27:10:26:11,380 INFO     [task.py:361] Building contexts for mmlu_security_studies on rank 3...\n",
      "2024-02-27:10:26:11,380 INFO     [task.py:361] Building contexts for mmlu_security_studies on rank 2...\n",
      "2024-02-27:10:26:11,381 INFO     [task.py:361] Building contexts for mmlu_security_studies on rank 0...\n",
      "2024-02-27:10:26:11,382 INFO     [task.py:361] Building contexts for mmlu_security_studies on rank 1...\n",
      "2024-02-27:10:26:12,462 INFO     [task.py:361] Building contexts for mmlu_high_school_government_and_politics on rank 2...\n",
      "2024-02-27:10:26:12,462 INFO     [task.py:361] Building contexts for mmlu_high_school_government_and_politics on rank 3...\n",
      "2024-02-27:10:26:12,462 INFO     [task.py:361] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "2024-02-27:10:26:12,462 INFO     [task.py:361] Building contexts for mmlu_high_school_government_and_politics on rank 1...\n",
      "2024-02-27:10:26:13,295 INFO     [task.py:361] Building contexts for mmlu_high_school_microeconomics on rank 3...\n",
      "2024-02-27:10:26:13,295 INFO     [task.py:361] Building contexts for mmlu_high_school_microeconomics on rank 2...\n",
      "2024-02-27:10:26:13,296 INFO     [task.py:361] Building contexts for mmlu_high_school_microeconomics on rank 1...\n",
      "2024-02-27:10:26:13,296 INFO     [task.py:361] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "2024-02-27:10:26:14,302 INFO     [task.py:361] Building contexts for mmlu_econometrics on rank 2...\n",
      "2024-02-27:10:26:14,302 INFO     [task.py:361] Building contexts for mmlu_econometrics on rank 0...\n",
      "2024-02-27:10:26:14,302 INFO     [task.py:361] Building contexts for mmlu_econometrics on rank 3...\n",
      "2024-02-27:10:26:14,304 INFO     [task.py:361] Building contexts for mmlu_econometrics on rank 1...\n",
      "2024-02-27:10:26:14,782 INFO     [task.py:361] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "2024-02-27:10:26:14,782 INFO     [task.py:361] Building contexts for mmlu_high_school_macroeconomics on rank 1...\n",
      "2024-02-27:10:26:14,782 INFO     [task.py:361] Building contexts for mmlu_high_school_macroeconomics on rank 3...\n",
      "2024-02-27:10:26:14,782 INFO     [task.py:361] Building contexts for mmlu_high_school_macroeconomics on rank 2...\n",
      "2024-02-27:10:26:16,453 INFO     [task.py:361] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "2024-02-27:10:26:16,453 INFO     [task.py:361] Building contexts for mmlu_high_school_geography on rank 3...\n",
      "2024-02-27:10:26:16,453 INFO     [task.py:361] Building contexts for mmlu_high_school_geography on rank 2...\n",
      "2024-02-27:10:26:16,454 INFO     [task.py:361] Building contexts for mmlu_high_school_geography on rank 1...\n",
      "2024-02-27:10:26:17,291 INFO     [task.py:361] Building contexts for mmlu_sociology on rank 3...\n",
      "2024-02-27:10:26:17,291 INFO     [task.py:361] Building contexts for mmlu_sociology on rank 2...\n",
      "2024-02-27:10:26:17,291 INFO     [task.py:361] Building contexts for mmlu_sociology on rank 0...\n",
      "2024-02-27:10:26:17,292 INFO     [task.py:361] Building contexts for mmlu_sociology on rank 1...\n",
      "2024-02-27:10:26:18,150 INFO     [task.py:361] Building contexts for mmlu_high_school_psychology on rank 3...\n",
      "2024-02-27:10:26:18,150 INFO     [task.py:361] Building contexts for mmlu_high_school_psychology on rank 2...\n",
      "2024-02-27:10:26:18,152 INFO     [task.py:361] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "2024-02-27:10:26:18,153 INFO     [task.py:361] Building contexts for mmlu_high_school_psychology on rank 1...\n",
      "2024-02-27:10:26:20,453 INFO     [task.py:361] Building contexts for mmlu_management on rank 0...\n",
      "2024-02-27:10:26:20,453 INFO     [task.py:361] Building contexts for mmlu_management on rank 3...\n",
      "2024-02-27:10:26:20,453 INFO     [task.py:361] Building contexts for mmlu_management on rank 1...\n",
      "2024-02-27:10:26:20,453 INFO     [task.py:361] Building contexts for mmlu_management on rank 2...\n",
      "2024-02-27:10:26:20,897 INFO     [task.py:361] Building contexts for mmlu_virology on rank 3...\n",
      "2024-02-27:10:26:20,897 INFO     [task.py:361] Building contexts for mmlu_virology on rank 0...\n",
      "2024-02-27:10:26:20,897 INFO     [task.py:361] Building contexts for mmlu_virology on rank 2...\n",
      "2024-02-27:10:26:20,899 INFO     [task.py:361] Building contexts for mmlu_virology on rank 1...\n",
      "2024-02-27:10:26:21,653 INFO     [task.py:361] Building contexts for mmlu_college_medicine on rank 3...\n",
      "2024-02-27:10:26:21,653 INFO     [task.py:361] Building contexts for mmlu_college_medicine on rank 2...\n",
      "2024-02-27:10:26:21,654 INFO     [task.py:361] Building contexts for mmlu_college_medicine on rank 0...\n",
      "2024-02-27:10:26:21,654 INFO     [task.py:361] Building contexts for mmlu_college_medicine on rank 1...\n",
      "2024-02-27:10:26:22,388 INFO     [task.py:361] Building contexts for mmlu_professional_accounting on rank 3...\n",
      "2024-02-27:10:26:22,389 INFO     [task.py:361] Building contexts for mmlu_professional_accounting on rank 2...\n",
      "2024-02-27:10:26:22,390 INFO     [task.py:361] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "2024-02-27:10:26:22,390 INFO     [task.py:361] Building contexts for mmlu_professional_accounting on rank 1...\n",
      "2024-02-27:10:26:23,578 INFO     [task.py:361] Building contexts for mmlu_business_ethics on rank 0...\n",
      "2024-02-27:10:26:23,578 INFO     [task.py:361] Building contexts for mmlu_business_ethics on rank 3...\n",
      "2024-02-27:10:26:23,578 INFO     [task.py:361] Building contexts for mmlu_business_ethics on rank 2...\n",
      "2024-02-27:10:26:23,578 INFO     [task.py:361] Building contexts for mmlu_business_ethics on rank 1...\n",
      "2024-02-27:10:26:24,042 INFO     [task.py:361] Building contexts for mmlu_marketing on rank 0...\n",
      "2024-02-27:10:26:24,042 INFO     [task.py:361] Building contexts for mmlu_marketing on rank 3...\n",
      "2024-02-27:10:26:24,042 INFO     [task.py:361] Building contexts for mmlu_marketing on rank 1...\n",
      "2024-02-27:10:26:24,042 INFO     [task.py:361] Building contexts for mmlu_marketing on rank 2...\n",
      "2024-02-27:10:26:25,153 INFO     [task.py:361] Building contexts for mmlu_nutrition on rank 3...\n",
      "2024-02-27:10:26:25,153 INFO     [task.py:361] Building contexts for mmlu_nutrition on rank 2...\n",
      "2024-02-27:10:26:25,153 INFO     [task.py:361] Building contexts for mmlu_nutrition on rank 0...\n",
      "2024-02-27:10:26:25,156 INFO     [task.py:361] Building contexts for mmlu_nutrition on rank 1...\n",
      "2024-02-27:10:26:26,613 INFO     [task.py:361] Building contexts for mmlu_global_facts on rank 2...\n",
      "2024-02-27:10:26:26,613 INFO     [task.py:361] Building contexts for mmlu_global_facts on rank 3...\n",
      "2024-02-27:10:26:26,614 INFO     [task.py:361] Building contexts for mmlu_global_facts on rank 0...\n",
      "2024-02-27:10:26:26,615 INFO     [task.py:361] Building contexts for mmlu_global_facts on rank 1...\n",
      "2024-02-27:10:26:27,068 INFO     [task.py:361] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "2024-02-27:10:26:27,068 INFO     [task.py:361] Building contexts for mmlu_miscellaneous on rank 3...\n",
      "2024-02-27:10:26:27,068 INFO     [task.py:361] Building contexts for mmlu_miscellaneous on rank 1...\n",
      "2024-02-27:10:26:27,068 INFO     [task.py:361] Building contexts for mmlu_miscellaneous on rank 2...\n",
      "2024-02-27:10:26:30,443 INFO     [task.py:361] Building contexts for mmlu_human_aging on rank 3...\n",
      "2024-02-27:10:26:30,443 INFO     [task.py:361] Building contexts for mmlu_human_aging on rank 1...\n",
      "2024-02-27:10:26:30,443 INFO     [task.py:361] Building contexts for mmlu_human_aging on rank 0...\n",
      "2024-02-27:10:26:30,445 INFO     [task.py:361] Building contexts for mmlu_human_aging on rank 2...\n",
      "2024-02-27:10:26:31,398 INFO     [task.py:361] Building contexts for mmlu_clinical_knowledge on rank 1...\n",
      "2024-02-27:10:26:31,398 INFO     [task.py:361] Building contexts for mmlu_clinical_knowledge on rank 3...\n",
      "2024-02-27:10:26:31,398 INFO     [task.py:361] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "2024-02-27:10:26:31,398 INFO     [task.py:361] Building contexts for mmlu_clinical_knowledge on rank 2...\n",
      "2024-02-27:10:26:32,551 INFO     [task.py:361] Building contexts for mmlu_professional_medicine on rank 3...\n",
      "2024-02-27:10:26:32,551 INFO     [task.py:361] Building contexts for mmlu_professional_medicine on rank 2...\n",
      "2024-02-27:10:26:32,552 INFO     [task.py:361] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "2024-02-27:10:26:32,552 INFO     [task.py:361] Building contexts for mmlu_professional_medicine on rank 1...\n",
      "2024-02-27:10:26:33,709 INFO     [task.py:361] Building contexts for mmlu_medical_genetics on rank 3...\n",
      "2024-02-27:10:26:33,709 INFO     [task.py:361] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "2024-02-27:10:26:33,709 INFO     [task.py:361] Building contexts for mmlu_medical_genetics on rank 2...\n",
      "2024-02-27:10:26:33,711 INFO     [task.py:361] Building contexts for mmlu_medical_genetics on rank 1...\n",
      "2024-02-27:10:26:34,142 INFO     [task.py:361] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "2024-02-27:10:26:34,142 INFO     [task.py:361] Building contexts for mmlu_high_school_computer_science on rank 3...\n",
      "2024-02-27:10:26:34,142 INFO     [task.py:361] Building contexts for mmlu_high_school_computer_science on rank 2...\n",
      "2024-02-27:10:26:34,144 INFO     [task.py:361] Building contexts for mmlu_high_school_computer_science on rank 1...\n",
      "2024-02-27:10:26:34,567 INFO     [task.py:361] Building contexts for mmlu_college_physics on rank 3...\n",
      "2024-02-27:10:26:34,567 INFO     [task.py:361] Building contexts for mmlu_college_physics on rank 0...\n",
      "2024-02-27:10:26:34,567 INFO     [task.py:361] Building contexts for mmlu_college_physics on rank 2...\n",
      "2024-02-27:10:26:34,568 INFO     [task.py:361] Building contexts for mmlu_college_physics on rank 1...\n",
      "2024-02-27:10:26:34,997 INFO     [task.py:361] Building contexts for mmlu_high_school_mathematics on rank 3...\n",
      "2024-02-27:10:26:34,997 INFO     [task.py:361] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "2024-02-27:10:26:34,997 INFO     [task.py:361] Building contexts for mmlu_high_school_mathematics on rank 2...\n",
      "2024-02-27:10:26:34,997 INFO     [task.py:361] Building contexts for mmlu_high_school_mathematics on rank 1...\n",
      "2024-02-27:10:26:36,136 INFO     [task.py:361] Building contexts for mmlu_computer_security on rank 3...\n",
      "2024-02-27:10:26:36,136 INFO     [task.py:361] Building contexts for mmlu_computer_security on rank 0...\n",
      "2024-02-27:10:26:36,136 INFO     [task.py:361] Building contexts for mmlu_computer_security on rank 1...\n",
      "2024-02-27:10:26:36,137 INFO     [task.py:361] Building contexts for mmlu_computer_security on rank 2...\n",
      "2024-02-27:10:26:36,563 INFO     [task.py:361] Building contexts for mmlu_high_school_chemistry on rank 2...\n",
      "2024-02-27:10:26:36,563 INFO     [task.py:361] Building contexts for mmlu_high_school_chemistry on rank 3...\n",
      "2024-02-27:10:26:36,565 INFO     [task.py:361] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "2024-02-27:10:26:36,567 INFO     [task.py:361] Building contexts for mmlu_high_school_chemistry on rank 1...\n",
      "2024-02-27:10:26:37,430 INFO     [task.py:361] Building contexts for mmlu_high_school_biology on rank 3...\n",
      "2024-02-27:10:26:37,430 INFO     [task.py:361] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "2024-02-27:10:26:37,430 INFO     [task.py:361] Building contexts for mmlu_high_school_biology on rank 2...\n",
      "2024-02-27:10:26:37,431 INFO     [task.py:361] Building contexts for mmlu_high_school_biology on rank 1...\n",
      "2024-02-27:10:26:38,755 INFO     [task.py:361] Building contexts for mmlu_astronomy on rank 3...\n",
      "2024-02-27:10:26:38,755 INFO     [task.py:361] Building contexts for mmlu_astronomy on rank 0...\n",
      "2024-02-27:10:26:38,755 INFO     [task.py:361] Building contexts for mmlu_astronomy on rank 1...\n",
      "2024-02-27:10:26:38,755 INFO     [task.py:361] Building contexts for mmlu_astronomy on rank 2...\n",
      "2024-02-27:10:26:39,405 INFO     [task.py:361] Building contexts for mmlu_high_school_statistics on rank 3...\n",
      "2024-02-27:10:26:39,405 INFO     [task.py:361] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "2024-02-27:10:26:39,405 INFO     [task.py:361] Building contexts for mmlu_high_school_statistics on rank 1...\n",
      "2024-02-27:10:26:39,405 INFO     [task.py:361] Building contexts for mmlu_high_school_statistics on rank 2...\n",
      "2024-02-27:10:26:40,333 INFO     [task.py:361] Building contexts for mmlu_college_biology on rank 3...\n",
      "2024-02-27:10:26:40,333 INFO     [task.py:361] Building contexts for mmlu_college_biology on rank 1...\n",
      "2024-02-27:10:26:40,333 INFO     [task.py:361] Building contexts for mmlu_college_biology on rank 2...\n",
      "2024-02-27:10:26:40,333 INFO     [task.py:361] Building contexts for mmlu_college_biology on rank 0...\n",
      "2024-02-27:10:26:41,003 INFO     [task.py:361] Building contexts for mmlu_college_chemistry on rank 1...\n",
      "2024-02-27:10:26:41,003 INFO     [task.py:361] Building contexts for mmlu_college_chemistry on rank 3...\n",
      "2024-02-27:10:26:41,003 INFO     [task.py:361] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "2024-02-27:10:26:41,006 INFO     [task.py:361] Building contexts for mmlu_college_chemistry on rank 2...\n",
      "2024-02-27:10:26:41,436 INFO     [task.py:361] Building contexts for mmlu_machine_learning on rank 3...\n",
      "2024-02-27:10:26:41,436 INFO     [task.py:361] Building contexts for mmlu_machine_learning on rank 0...\n",
      "2024-02-27:10:26:41,436 INFO     [task.py:361] Building contexts for mmlu_machine_learning on rank 2...\n",
      "2024-02-27:10:26:41,436 INFO     [task.py:361] Building contexts for mmlu_machine_learning on rank 1...\n",
      "2024-02-27:10:26:41,924 INFO     [task.py:361] Building contexts for mmlu_elementary_mathematics on rank 3...\n",
      "2024-02-27:10:26:41,924 INFO     [task.py:361] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "2024-02-27:10:26:41,924 INFO     [task.py:361] Building contexts for mmlu_elementary_mathematics on rank 1...\n",
      "2024-02-27:10:26:41,924 INFO     [task.py:361] Building contexts for mmlu_elementary_mathematics on rank 2...\n",
      "2024-02-27:10:26:43,538 INFO     [task.py:361] Building contexts for mmlu_conceptual_physics on rank 3...\n",
      "2024-02-27:10:26:43,538 INFO     [task.py:361] Building contexts for mmlu_conceptual_physics on rank 2...\n",
      "2024-02-27:10:26:43,540 INFO     [task.py:361] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "2024-02-27:10:26:43,540 INFO     [task.py:361] Building contexts for mmlu_conceptual_physics on rank 1...\n",
      "2024-02-27:10:26:44,543 INFO     [task.py:361] Building contexts for mmlu_abstract_algebra on rank 3...\n",
      "2024-02-27:10:26:44,543 INFO     [task.py:361] Building contexts for mmlu_abstract_algebra on rank 2...\n",
      "2024-02-27:10:26:44,544 INFO     [task.py:361] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "2024-02-27:10:26:44,544 INFO     [task.py:361] Building contexts for mmlu_abstract_algebra on rank 1...\n",
      "2024-02-27:10:26:44,973 INFO     [task.py:361] Building contexts for mmlu_college_mathematics on rank 3...\n",
      "2024-02-27:10:26:44,973 INFO     [task.py:361] Building contexts for mmlu_college_mathematics on rank 2...\n",
      "2024-02-27:10:26:44,973 INFO     [task.py:361] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "2024-02-27:10:26:44,975 INFO     [task.py:361] Building contexts for mmlu_college_mathematics on rank 1...\n",
      "2024-02-27:10:26:45,402 INFO     [task.py:361] Building contexts for mmlu_high_school_physics on rank 3...\n",
      "2024-02-27:10:26:45,402 INFO     [task.py:361] Building contexts for mmlu_high_school_physics on rank 2...\n",
      "2024-02-27:10:26:45,403 INFO     [task.py:361] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "2024-02-27:10:26:45,403 INFO     [task.py:361] Building contexts for mmlu_high_school_physics on rank 1...\n",
      "2024-02-27:10:26:46,039 INFO     [task.py:361] Building contexts for mmlu_anatomy on rank 1...\n",
      "2024-02-27:10:26:46,039 INFO     [task.py:361] Building contexts for mmlu_anatomy on rank 0...\n",
      "2024-02-27:10:26:46,039 INFO     [task.py:361] Building contexts for mmlu_anatomy on rank 3...\n",
      "2024-02-27:10:26:46,040 INFO     [task.py:361] Building contexts for mmlu_anatomy on rank 2...\n",
      "2024-02-27:10:26:46,627 INFO     [task.py:361] Building contexts for mmlu_college_computer_science on rank 1...\n",
      "2024-02-27:10:26:46,627 INFO     [task.py:361] Building contexts for mmlu_college_computer_science on rank 3...\n",
      "2024-02-27:10:26:46,627 INFO     [task.py:361] Building contexts for mmlu_college_computer_science on rank 2...\n",
      "2024-02-27:10:26:46,627 INFO     [task.py:361] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "2024-02-27:10:26:47,056 INFO     [task.py:361] Building contexts for mmlu_electrical_engineering on rank 3...\n",
      "2024-02-27:10:26:47,056 INFO     [task.py:361] Building contexts for mmlu_electrical_engineering on rank 2...\n",
      "2024-02-27:10:26:47,057 INFO     [task.py:361] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "2024-02-27:10:26:47,059 INFO     [task.py:361] Building contexts for mmlu_electrical_engineering on rank 1...\n",
      "2024-02-27:10:26:47,673 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:26:47,673 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:26:47,673 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:26:47,673 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      " 65%|███████████████████████▉             | 9141/14116 [01:17<00:43, 113.62it/s]"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks mmlu \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruthfulQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-27:10:21:38,920 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:21:38,920 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:21:39,034 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:21:39,034 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:21:39,059 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:21:39,059 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:21:39,337 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:21:39,338 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:21:44,432 INFO     [__main__.py:285] Selected Tasks: ['truthfulqa_mc2']\n",
      "2024-02-27:10:21:44,432 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:21:44,433 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:21:44,433 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:21:44,433 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:21:44,535 INFO     [__main__.py:285] Selected Tasks: ['truthfulqa_mc2']\n",
      "2024-02-27:10:21:44,535 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:21:44,535 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:21:44,535 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:21:44,535 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:21:45,524 INFO     [__main__.py:285] Selected Tasks: ['truthfulqa_mc2']\n",
      "2024-02-27:10:21:45,525 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:21:45,525 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:21:45,525 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:21:45,525 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:21:45,766 INFO     [__main__.py:285] Selected Tasks: ['truthfulqa_mc2']\n",
      "2024-02-27:10:21:45,767 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:21:45,769 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:21:45,769 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:21:45,769 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "[2024-02-27 10:21:46,230] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-27 10:21:46,796] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:21:46,985 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "[2024-02-27 10:21:47,297] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:21:47,538 INFO     [huggingface.py:322] Using 4 devices with data parallelism\n",
      "2024-02-27:10:21:47,538 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:21:47,990 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "[2024-02-27 10:21:48,142] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:21:48,870 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 4315.13it/s]\n",
      "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 797.55it/s]\n",
      "Generating validation split: 100%|██| 817/817 [00:00<00:00, 69278.98 examples/s]\n",
      "2024-02-27:10:21:56,171 INFO     [evaluator.py:178] num_fewshot has been set to 0 for truthfulqa_mc2 in its config. Manual configuration will be ignored.\n",
      "2024-02-27:10:21:56,173 INFO     [task.py:361] Building contexts for truthfulqa_mc2 on rank 3...\n",
      "2024-02-27:10:21:56,179 INFO     [evaluator.py:178] num_fewshot has been set to 0 for truthfulqa_mc2 in its config. Manual configuration will be ignored.\n",
      "2024-02-27:10:21:56,181 INFO     [task.py:361] Building contexts for truthfulqa_mc2 on rank 1...\n",
      "2024-02-27:10:21:56,889 INFO     [evaluator.py:178] num_fewshot has been set to 0 for truthfulqa_mc2 in its config. Manual configuration will be ignored.\n",
      "2024-02-27:10:21:56,892 INFO     [task.py:361] Building contexts for truthfulqa_mc2 on rank 0...\n",
      "2024-02-27:10:21:58,610 INFO     [evaluator.py:178] num_fewshot has been set to 0 for truthfulqa_mc2 in its config. Manual configuration will be ignored.\n",
      "2024-02-27:10:21:58,612 INFO     [task.py:361] Building contexts for truthfulqa_mc2 on rank 2...\n",
      "2024-02-27:10:21:59,824 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:21:59,824 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:21:59,840 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:21:59,850 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "100%|███████████████████████████████████████| 1540/1540 [00:38<00:00, 40.16it/s]\n",
      "hf (pretrained=EleutherAI/pythia-70m), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 1\n",
      "|    Tasks     |Version|Filter|n-shot|Metric|Value|   |Stderr|\n",
      "|--------------|------:|------|-----:|------|-----|---|------|\n",
      "|truthfulqa_mc2|      2|none  |     0|acc   |NaN  |±  |NaN   |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks truthfulqa_mc2 \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winogrande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-27:10:17:00,152 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:17:00,153 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:17:00,459 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:17:00,459 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:17:00,546 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:17:00,546 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:17:00,939 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-27:10:17:00,939 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-27:10:17:05,775 INFO     [__main__.py:285] Selected Tasks: ['winogrande']\n",
      "2024-02-27:10:17:05,775 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:17:05,776 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:17:05,776 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:17:05,776 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:17:06,111 INFO     [__main__.py:285] Selected Tasks: ['winogrande']\n",
      "2024-02-27:10:17:06,111 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:17:06,112 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:17:06,112 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:17:06,112 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:17:06,300 INFO     [__main__.py:285] Selected Tasks: ['winogrande']\n",
      "2024-02-27:10:17:06,300 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:17:06,301 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:17:06,301 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:17:06,301 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-27:10:17:06,548 INFO     [__main__.py:285] Selected Tasks: ['winogrande']\n",
      "2024-02-27:10:17:06,548 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-27:10:17:06,549 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-27:10:17:06,549 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-27:10:17:06,549 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "[2024-02-27 10:17:07,861] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-27 10:17:07,969] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-27 10:17:08,060] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-27 10:17:08,395] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:17:08,565 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:17:08,797 INFO     [huggingface.py:322] Using 4 devices with data parallelism\n",
      "2024-02-27:10:17:08,797 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:17:09,286 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-27:10:17:09,637 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-27:10:17:13,164 WARNING  [evaluator.py:182] Overwriting default num_fewshot of winogrande from None to 5\n",
      "2024-02-27:10:17:13,165 INFO     [task.py:361] Building contexts for winogrande on rank 0...\n",
      "2024-02-27:10:17:13,815 WARNING  [evaluator.py:182] Overwriting default num_fewshot of winogrande from None to 5\n",
      "2024-02-27:10:17:13,817 INFO     [task.py:361] Building contexts for winogrande on rank 1...\n",
      "2024-02-27:10:17:13,840 WARNING  [evaluator.py:182] Overwriting default num_fewshot of winogrande from None to 5\n",
      "2024-02-27:10:17:13,842 INFO     [task.py:361] Building contexts for winogrande on rank 2...\n",
      "2024-02-27:10:17:14,423 WARNING  [evaluator.py:182] Overwriting default num_fewshot of winogrande from None to 5\n",
      "2024-02-27:10:17:14,424 INFO     [task.py:361] Building contexts for winogrande on rank 3...\n",
      "2024-02-27:10:17:15,443 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:17:15,446 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:17:15,447 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "2024-02-27:10:17:15,448 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "100%|█████████████████████████████████████████| 634/634 [00:14<00:00, 42.72it/s]\n",
      "hf (pretrained=EleutherAI/pythia-70m), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n",
      "|  Tasks   |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
      "|----------|------:|------|-----:|------|-----:|---|-----:|\n",
      "|winogrande|      1|none  |     5|acc   |0.4964|±  |0.0141|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks winogrande \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-28:04:49:40,306 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:04:49:40,306 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:04:49:45,828 INFO     [__main__.py:285] Selected Tasks: ['winogrande']\n",
      "2024-02-28:04:49:45,828 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:04:49:45,829 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:04:49:45,829 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:04:49:45,829 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-28:04:49:46,316 INFO     [huggingface.py:161] Using device 'cuda'\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.54s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.16.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:04:50:21,015 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-28:04:50:26,131 WARNING  [evaluator.py:182] Overwriting default num_fewshot of winogrande from None to 5\n",
      "2024-02-28:04:50:26,134 INFO     [task.py:361] Building contexts for winogrande on rank 0...\n",
      "2024-02-28:04:50:26,325 INFO     [evaluator.py:369] Running loglikelihood requests\n",
      "100%|███████████████████████████████████████| 2534/2534 [01:29<00:00, 28.31it/s]\n",
      "hf (pretrained=microsoft/phi-2), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n",
      "|  Tasks   |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
      "|----------|------:|------|-----:|------|-----:|---|-----:|\n",
      "|winogrande|      1|none  |     5|acc   |0.5107|±  | 0.014|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=microsoft/phi-2 \\\n",
    "    --tasks winogrande \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-28:04:46:36,106 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:04:46:36,107 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:04:46:36,350 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:04:46:36,350 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:04:46:36,356 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:04:46:36,356 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:04:46:36,419 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:04:46:36,419 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:04:46:41,780 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:04:46:41,781 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:04:46:41,781 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:04:46:41,781 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:04:46:41,781 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-28:04:46:41,959 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:04:46:41,960 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:04:46:41,960 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:04:46:41,960 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:04:46:41,960 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-28:04:46:42,020 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:04:46:42,020 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:04:46:42,021 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:04:46:42,021 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:04:46:42,021 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-28:04:46:42,118 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:04:46:42,119 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:04:46:42,119 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:04:46:42,120 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:04:46:42,120 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.11s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.23.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.20.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.33s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.1.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.20.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:02<00:02,  2.55s/it][2024-02-28 04:47:16,025] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-28 04:47:16,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:04:47:16,720 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:04:47:16,854 INFO     [huggingface.py:322] Using 4 devices with data parallelism\n",
      "2024-02-28:04:47:16,854 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.74s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.27.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.15.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.67s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.14.self_attn.v_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.19.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2024-02-28 04:47:18,648] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:04:47:19,377 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "[2024-02-28 04:47:19,738] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:04:47:20,419 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-28:04:47:27,739 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:04:47:27,740 INFO     [task.py:361] Building contexts for gsm8k on rank 0...\n",
      "2024-02-28:04:47:28,437 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:04:47:28,437 INFO     [task.py:361] Building contexts for gsm8k on rank 3...\n",
      "2024-02-28:04:47:31,644 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:04:47:31,645 INFO     [task.py:361] Building contexts for gsm8k on rank 1...\n",
      "2024-02-28:04:47:31,771 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:04:47:31,772 INFO     [task.py:361] Building contexts for gsm8k on rank 2...\n",
      "2024-02-28:04:47:35,443 INFO     [evaluator.py:369] Running generate_until requests\n",
      "2024-02-28:04:47:35,447 INFO     [evaluator.py:369] Running generate_until requests\n",
      "2024-02-28:04:47:35,447 INFO     [evaluator.py:369] Running generate_until requests\n",
      "  0%|                                                   | 0/330 [00:00<?, ?it/s]2024-02-28:04:47:35,450 INFO     [evaluator.py:369] Running generate_until requests\n",
      "  0%|                                         | 1/330 [00:12<1:08:49, 12.55s/it]^C\n",
      "[2024-02-28 04:47:54,951] torch.distributed.elastic.agent.server.api: [WARNING] Received 2 death signal, shutting down workers\n",
      "[2024-02-28 04:47:54,951] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 289454 closing signal SIGINT\n",
      "[2024-02-28 04:47:54,951] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 289455 closing signal SIGINT\n",
      "[2024-02-28 04:47:54,951] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 289456 closing signal SIGINT\n",
      "[2024-02-28 04:47:54,952] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 289457 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 362, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 362, in <module>\n",
      "Traceback (most recent call last):\n",
      "    Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "cli_evaluate()\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 362, in <module>\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 362, in <module>\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 288, in cli_evaluate\n",
      "    cli_evaluate()\n",
      "    results = evaluator.simple_evaluate(\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 288, in cli_evaluate\n",
      "              ^^^^^^^^^^^    ^results = evaluator.simple_evaluate(^\n",
      "^^^^^^ ^ ^ ^ ^     ^ cli_evaluate()^ \n",
      "^ \n",
      "        File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "^^^^^^^^^^^^^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 288, in cli_evaluate\n",
      "^^    ^cli_evaluate()^\n",
      "^^^^^^^    ^return fn(*args, **kwargs)^\n",
      "\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/__main__.py\", line 288, in cli_evaluate\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "    results = evaluator.simple_evaluate(\n",
      "                   ^     ^ results = evaluator.simple_evaluate(^     \n",
      "^ return fn(*args, **kwargs)^  \n",
      "^ ^^ ^^ ^^ ^^  ^^  ^^  ^^  ^^  ^^  ^^  ^^  ^^  ^^  \n",
      "^ ^^^^^^^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 190, in simple_evaluate\n",
      "^^^^^^^^^^^^^^^^^^^^^^^    ^^^^results = evaluate(^^^\n",
      "^^\n",
      "^^^ ^^   File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "^^ ^^ ^^ \n",
      "^ ^ ^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 190, in simple_evaluate\n",
      " ^ ^ ^ ^ \n",
      "     return fn(*args, **kwargs) \n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "^^    ^results = evaluate(^\n",
      "^^^^ ^ \n",
      "       File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "                   return fn(*args, **kwargs)  \n",
      "^ ^^^^^    ^^return fn(*args, **kwargs)^^\n",
      "^^ ^^ ^^ ^^  ^^   ^\n",
      "  ^^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "  ^  ^  ^  ^  ^^ \n",
      "^ ^^^      File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 190, in simple_evaluate\n",
      "^^return fn(*args, **kwargs)^^\n",
      "^^^^^^^^ ^^ ^^     ^^ results = evaluate(^^ \n",
      "^^ ^^ ^ ^ ^ ^ ^ ^ ^ \n",
      " ^ ^^ ^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 190, in simple_evaluate\n",
      " ^ ^ ^   File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 380, in evaluate\n",
      "^ ^ ^ ^ ^^^    ^^results = evaluate(^^\n",
      "^^^^^^ ^^ ^    ^ ^^resps = getattr(lm, reqtype)(cloned_reqs) \n",
      "\n",
      "\n",
      "    File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "   File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 380, in evaluate\n",
      "         ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
      "     return fn(*args, **kwargs)^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/utils.py\", line 288, in _wrapper\n",
      "\n",
      "    ^resps = getattr(lm, reqtype)(cloned_reqs)^\n",
      "^^^ ^ ^ ^ ^  ^  ^  ^  ^      ^  return fn(*args, **kwargs)^  \n",
      "^^ ^^ ^^ ^ ^ ^ ^ ^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^^^^^^^^^^\n",
      "^^^^^^^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1164, in generate_until\n",
      "^^\n",
      "^^^^^^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 380, in evaluate\n",
      "^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^    \n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/evaluator.py\", line 380, in evaluate\n",
      "resps = getattr(lm, reqtype)(cloned_reqs)\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1164, in generate_until\n",
      "            ^^^^^^^^^^^^^    ^resps = getattr(lm, reqtype)(cloned_reqs)^\n",
      "^^^^^^^^^^    ^cont = self._model_generate(^\n",
      "^ ^ ^  ^  ^  ^  \n",
      "        File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1164, in generate_until\n",
      "      ^     ^^cont = self._model_generate(^^\n",
      "^^^^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^    ^^^cont = self._model_generate(^^^\n",
      "^^\n",
      "^^^ ^^^   File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 754, in _model_generate\n",
      "^^ ^^^ ^^ ^^ ^^ ^^ ^^ \n",
      "^ ^ ^^\n",
      "  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 1164, in generate_until\n",
      "^^  File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 754, in _model_generate\n",
      "^^^^^^^^^^^^^^    ^return self.model.generate(^\n",
      "^^\n",
      "    File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 754, in _model_generate\n",
      "         ^^^^^^^^^^^^^^^^^    ^return self.model.generate(^\n",
      "^\n",
      "      File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "       ^^^^    ^cont = self._model_generate(    ^\n",
      "return self.model.generate(^\n",
      "^     ^ return func(*args, **kwargs) ^ \n",
      " ^  ^  ^  ^   ^   ^   ^   ^   ^  ^^^ ^^\n",
      " ^ ^^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "^ ^^^^^^^^^^^^^^^^^^    ^^^return func(*args, **kwargs)^^^\n",
      "^^^^^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^\n",
      "\n",
      " ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "^   File \"/home/ubuntu/hieu.nn/lm-evaluation-harness/lm_eval/models/huggingface.py\", line 754, in _model_generate\n",
      "^ ^ ^ \n",
      "^^^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 1718, in generate\n",
      "^^^^^^^^^^    ^return func(*args, **kwargs)^\n",
      "^^^\n",
      "     File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 1718, in generate\n",
      "        ^^^^^    ^return self.model.generate(^\n",
      "^^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
      "^^^^^^^^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 1718, in generate\n",
      "^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           return self.greedy_search( \n",
      "   ^^^^ ^ ^ ^ ^ ^ ^ ^     ^return self.greedy_search( ^\n",
      " ^ ^^^ ^^ ^^ ^^ ^ ^^ ^^ \n",
      "^ ^     ^ return self.greedy_search(^ \n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 1718, in generate\n",
      "^^^^^ ^^ ^^ ^^ ^^ ^^ ^\n",
      " ^ ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 2579, in greedy_search\n",
      "^ ^ ^^^^^^^^^^^^^^\n",
      "^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 2579, in greedy_search\n",
      "^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 2579, in greedy_search\n",
      "    return self.greedy_search(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/generation/utils.py\", line 2579, in greedy_search\n",
      "    outputs = self(\n",
      "              ^^^^^\n",
      "    outputs = self(\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "           outputs = self( \n",
      "           ^ ^ ^ ^ ^ \n",
      "     File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      " ^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    outputs = self(\n",
      "              ^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^    ^return self._call_impl(*args, **kwargs)^\n",
      "^    ^return self._call_impl(*args, **kwargs)^\n",
      "^^ ^ ^ ^ ^ \n",
      "     File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "         ^ ^ ^ ^     ^return self._call_impl(*args, **kwargs) ^\n",
      "^^^^^^^^^^^ ^^ ^^ ^^ ^^ ^^ ^^^ ^^ ^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^    ^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "return forward_call(*args, **kwargs)^^\n",
      "^^^^^^^^^^^ ^^ ^\n",
      " ^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      " ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^\n",
      "^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 636, in forward\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^    ^return forward_call(*args, **kwargs)^\n",
      "^^^^^^^^^^^^ ^ ^     ^return model_forward(*args, **kwargs) ^\n",
      " ^ ^ \n",
      "      return forward_call(*args, **kwargs)    File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 636, in forward\n",
      "\n",
      "   ^ ^ ^  ^  ^   ^  ^  ^ ^^ ^^^ ^^ ^^ ^^ ^^^^^    ^^^return model_forward(*args, **kwargs)^^^\n",
      "^^^^^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ \n",
      "^^ ^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 636, in forward\n",
      "^^^^^^^^^^^^^^^\n",
      "^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 624, in __call__\n",
      "^^^^^^^^\n",
      "^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 636, in forward\n",
      "^^^^^^^^^^^    ^return model_forward(*args, **kwargs)^\n",
      "^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 624, in __call__\n",
      "           ^^^^^^^^    ^return convert_to_fp32(self.model_forward(*args, **kwargs))^\n",
      "^^^^^^^^^^^^     ^return model_forward(*args, **kwargs) ^\n",
      " ^ ^ ^ ^^      ^  return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "  \n",
      "    File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 624, in __call__\n",
      "                     ^  ^  ^  ^ ^  ^  ^      ^return convert_to_fp32(self.model_forward(*args, **kwargs))  ^\n",
      "  ^  ^^  ^^  ^^  ^^   ^^  ^^  ^^  ^^  ^^   ^^  ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ \n",
      "^^ ^^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/accelerate/utils/operations.py\", line 624, in __call__\n",
      "^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^    ^^return convert_to_fp32(self.model_forward(*args, **kwargs))  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "^^\n",
      "^^^^^^^^ ^^ ^^ ^    ^ ^return func(*args, **kwargs)\n",
      " ^ \n",
      "^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      " ^ ^   ^  ^  ^      ^return func(*args, **kwargs)  ^\n",
      "  ^  ^  ^   ^   \n",
      "  ^^  ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      " ^  ^  ^  ^  ^  ^ ^^^    ^^^return func(*args, **kwargs)^^^\n",
      "^^^^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^\n",
      "^ ^^  ^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 1040, in forward\n",
      " ^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 1040, in forward\n",
      "^^^^^^^^^^^^^^^^^^^\n",
      "^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/amp/autocast_mode.py\", line 16, in decorate_autocast\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 1040, in forward\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 1040, in forward\n",
      "    outputs = self.model(\n",
      "    outputs = self.model(     \n",
      "     outputs = self.model(outputs = self.model( \n",
      " \n",
      "                                          ^   ^   ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "^^^\n",
      "^^^\n",
      "\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           return self._call_impl(*args, **kwargs)         \n",
      "return self._call_impl(*args, **kwargs) return self._call_impl(*args, **kwargs)\n",
      " \n",
      " ^ ^ ^ ^  ^   ^   ^   ^   ^   ^   ^   ^  ^^  ^^  ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "^^\n",
      "^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^    ^return forward_call(*args, **kwargs)^\n",
      "^^    ^return forward_call(*args, **kwargs)^\n",
      " ^     ^return forward_call(*args, **kwargs) \n",
      "\n",
      "      File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 919, in forward\n",
      "                 ^  ^  ^  ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^layer_outputs = decoder_layer(^^^\n",
      "^^^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^^ ^^^ ^^^ ^^^ ^^^ \n",
      "^^ ^^^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 919, in forward\n",
      "^ ^^ \n",
      "^ \n",
      "    File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 919, in forward\n",
      "   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 919, in forward\n",
      "  ^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    layer_outputs = decoder_layer(\n",
      "                  layer_outputs = decoder_layer( \n",
      "        layer_outputs = decoder_layer( \n",
      "    ^  ^  ^   ^  ^  ^  ^  ^  ^  ^      ^return self._call_impl(*args, **kwargs) \n",
      " ^  ^   ^  \n",
      "        File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "  ^  ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^\n",
      "^^\n",
      "^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "        return self._call_impl(*args, **kwargs) \n",
      "      ^^^^^^^ ^ ^ ^ ^ ^ ^ ^     ^return forward_call(*args, **kwargs) ^\n",
      " ^ ^^^^^ ^^ ^^    ^ ^return forward_call(*args, **kwargs)^ ^\n",
      "^ ^^ ^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^ \n",
      "^^^ ^^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "^^^^^^^^^^^^^^\n",
      "^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 661, in forward\n",
      "^^    ^return forward_call(*args, **kwargs)^\n",
      "^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 661, in forward\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 661, in forward\n",
      "    attn_outputs, self_attn_weights, present_key_value = self.self_attn(\n",
      "                attn_outputs, self_attn_weights, present_key_value = self.self_attn( \n",
      "         return forward_call(*args, **kwargs)  \n",
      "                attn_outputs, self_attn_weights, present_key_value = self.self_attn(   \n",
      "                               ^    ^   ^    ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^   ^ ^ ^ ^ ^ ^ ^ ^ \n",
      " ^  ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 661, in forward\n",
      " ^  ^  ^  ^  ^  ^ ^  ^  ^ ^\n",
      " ^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      " ^ ^ ^ ^ ^ ^ ^ ^^^^^^    ^attn_outputs, self_attn_weights, present_key_value = self.self_attn(^^\n",
      "^\n",
      "^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      " ^ ^ ^ ^ ^ ^ ^ ^ \n",
      "    File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "                                     return self._call_impl(*args, **kwargs) \n",
      "                ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^    ^^return self._call_impl(*args, **kwargs)^^\n",
      "^\n",
      "^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "^ ^ ^ ^     ^return self._call_impl(*args, **kwargs) ^\n",
      "^ ^ ^ ^  ^  ^  ^^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^\n",
      " ^^^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^return self._call_impl(*args, **kwargs)^^\n",
      "^^^^^^^^^^\n",
      " ^ ^  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      " ^ ^ ^ ^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    return forward_call(*args, **kwargs)  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "\n",
      "           ^^^^^^^^^^^^^^^^^^^^^    ^return forward_call(*args, **kwargs)^\n",
      "^^^^^    ^ return forward_call(*args, **kwargs)\n",
      " \n",
      "    File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 353, in forward\n",
      "             ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^query_states = torch.cat((query_rot, query_pass), dim=-1)^    ^\n",
      "^return forward_call(*args, **kwargs)^^\n",
      "^^^^^^^^^ ^ ^^ \n",
      "^  ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 391, in forward\n",
      " ^  ^  ^  \n",
      "       File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 350, in forward\n",
      " ^ ^ ^ ^ ^ ^ ^ ^ ^ ^     ^attn_output = self.dense(attn_output) ^\n",
      "^^^^^^^^^^^^     ^^query_rot, key_rot = apply_rotary_pos_emb(query_rot, key_rot, cos, sin, position_ids) ^^\n",
      " ^^ ^^ ^^^ ^ ^^ ^^ ^^  ^^ ^ ^ ^ ^ ^ \n",
      " ^  ^  ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 353, in forward\n",
      " ^  ^  ^^^ ^^ ^^ ^^ ^^^ ^^ ^^ ^^ ^^ ^^ ^^ ^    ^ ^query_states = torch.cat((query_rot, query_pass), dim=-1)^ ^\n",
      "^ ^^ \n",
      "^^^^^^KeyboardInterrupt^^^^\n",
      "^^ ^^ ^^ ^\n",
      " ^ ^   File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^return self._call_impl(*args, **kwargs)^^\n",
      "^^^^^^^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^\n",
      " ^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 197, in apply_rotary_pos_emb\n",
      "^^^^KeyboardInterrupt^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^    ^k_embed = (k * cos) + (rotate_half(k) * sin)^\n",
      "\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "                           ^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/models/phi/modeling_phi.py\", line 165, in rotate_half\n",
      "    def rotate_half(x):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=EleutherAI/pythia-70m \\\n",
    "    --tasks gsm8k \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ubuntu/miniconda3/envs/lang/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-02-28:03:34:27,576 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:03:34:27,576 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:03:34:27,605 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:03:34:27,606 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:03:34:27,733 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:03:34:27,733 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:03:34:27,737 INFO     [__main__.py:209] Verbosity set to INFO\n",
      "2024-02-28:03:34:27,738 INFO     [__init__.py:358] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n",
      "2024-02-28:03:34:32,171 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:03:34:32,171 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:03:34:32,171 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:03:34:32,171 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:03:34:32,172 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-28:03:34:32,787 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:03:34:32,787 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:03:34:32,788 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:03:34:32,788 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:03:34:32,788 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "2024-02-28:03:34:33,094 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:03:34:33,095 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:03:34:33,095 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:03:34:33,095 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:03:34:33,095 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "config.json: 100%|█████████████████████████████| 863/863 [00:00<00:00, 3.53MB/s]\n",
      "2024-02-28:03:34:33,148 INFO     [__main__.py:285] Selected Tasks: ['gsm8k']\n",
      "2024-02-28:03:34:33,148 INFO     [__main__.py:286] Loading selected tasks...\n",
      "2024-02-28:03:34:33,149 INFO     [evaluator.py:95] Setting random seed to 0\n",
      "2024-02-28:03:34:33,149 INFO     [evaluator.py:99] Setting numpy seed to 1234\n",
      "2024-02-28:03:34:33,149 INFO     [evaluator.py:103] Setting torch manual seed to 1234\n",
      "model.safetensors.index.json: 100%|████████| 35.7k/35.7k [00:00<00:00, 65.3MB/s]\n",
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 10.5M/5.00G [00:00<04:47, 17.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 21.0M/5.00G [00:01<03:57, 20.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 31.5M/5.00G [00:01<05:11, 15.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 41.9M/5.00G [00:02<04:41, 17.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 52.4M/5.00G [00:02<03:53, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 62.9M/5.00G [00:02<03:20, 24.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|    | 73.4M/5.00G [00:03<03:18, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|    | 83.9M/5.00G [00:03<03:10, 25.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|    | 94.4M/5.00G [00:04<03:03, 26.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|     | 105M/5.00G [00:04<02:51, 28.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|     | 115M/5.00G [00:04<02:49, 28.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 126M/5.00G [00:05<02:42, 30.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 136M/5.00G [00:05<02:42, 29.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 147M/5.00G [00:05<02:47, 28.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 157M/5.00G [00:06<02:43, 29.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 168M/5.00G [00:06<02:39, 30.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 178M/5.00G [00:06<02:32, 31.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 189M/5.00G [00:07<02:51, 28.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 199M/5.00G [00:07<02:37, 30.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 210M/5.00G [00:08<03:02, 26.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 220M/5.00G [00:08<02:47, 28.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 231M/5.00G [00:09<03:28, 22.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 241M/5.00G [00:09<04:17, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 252M/5.00G [00:10<03:49, 20.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 262M/5.00G [00:10<03:26, 22.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▎    | 273M/5.00G [00:11<03:41, 21.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 283M/5.00G [00:11<03:27, 22.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 294M/5.00G [00:11<03:18, 23.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 304M/5.00G [00:12<04:28, 17.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 315M/5.00G [00:13<03:46, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 325M/5.00G [00:13<03:22, 23.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 336M/5.00G [00:14<03:34, 21.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 346M/5.00G [00:14<03:39, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 357M/5.00G [00:14<03:11, 24.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▎    | 367M/5.00G [00:15<02:55, 26.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 377M/5.00G [00:15<03:05, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 388M/5.00G [00:16<02:52, 26.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 398M/5.00G [00:16<02:41, 28.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 409M/5.00G [00:17<03:52, 19.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 419M/5.00G [00:17<03:38, 20.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 430M/5.00G [00:18<03:15, 23.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 440M/5.00G [00:18<03:02, 24.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 451M/5.00G [00:18<02:47, 27.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 461M/5.00G [00:18<02:38, 28.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▍    | 472M/5.00G [00:19<02:34, 29.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 482M/5.00G [00:19<02:24, 31.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▍    | 493M/5.00G [00:20<02:44, 27.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▌    | 503M/5.00G [00:20<02:29, 30.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▌    | 514M/5.00G [00:20<02:18, 32.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▌    | 524M/5.00G [00:20<02:11, 34.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 535M/5.00G [00:21<02:07, 34.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 545M/5.00G [00:21<02:08, 34.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 556M/5.00G [00:21<02:07, 34.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|▌    | 566M/5.00G [00:22<03:06, 23.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 577M/5.00G [00:22<02:58, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 587M/5.00G [00:23<02:53, 25.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 598M/5.00G [00:23<02:42, 27.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 608M/5.00G [00:24<03:00, 24.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|▌    | 619M/5.00G [00:24<02:43, 26.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 629M/5.00G [00:24<02:32, 28.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 640M/5.00G [00:25<02:50, 25.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 650M/5.00G [00:25<02:39, 27.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 661M/5.00G [00:25<02:33, 28.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|▋    | 671M/5.00G [00:26<02:25, 29.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 682M/5.00G [00:26<02:49, 25.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 692M/5.00G [00:27<02:37, 27.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 703M/5.00G [00:27<03:30, 20.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 713M/5.00G [00:28<03:30, 20.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|▋    | 724M/5.00G [00:28<03:18, 21.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▋    | 734M/5.00G [00:29<03:03, 23.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▋    | 744M/5.00G [00:29<03:18, 21.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▊    | 755M/5.00G [00:30<02:58, 23.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|▊    | 765M/5.00G [00:30<02:52, 24.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 776M/5.00G [00:31<03:14, 21.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 786M/5.00G [00:31<03:33, 19.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 797M/5.00G [00:32<03:05, 22.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 807M/5.00G [00:32<03:36, 19.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|▊    | 818M/5.00G [00:34<04:50, 14.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 828M/5.00G [00:34<04:04, 17.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 839M/5.00G [00:34<03:25, 20.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 849M/5.00G [00:35<03:47, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 860M/5.00G [00:35<03:17, 20.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|▊    | 870M/5.00G [00:36<03:02, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 881M/5.00G [00:36<02:48, 24.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 891M/5.00G [00:37<03:05, 22.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 902M/5.00G [00:37<02:48, 24.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 912M/5.00G [00:37<02:34, 26.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|▉    | 923M/5.00G [00:38<02:28, 27.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 933M/5.00G [00:38<02:44, 24.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 944M/5.00G [00:39<03:32, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 954M/5.00G [00:39<03:11, 21.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|▉    | 965M/5.00G [00:40<04:07, 16.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 975M/5.00G [00:41<03:36, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 986M/5.00G [00:41<03:40, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▉    | 996M/5.00G [00:42<03:37, 18.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▊   | 1.01G/5.00G [00:42<03:31, 18.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|▊   | 1.02G/5.00G [00:43<03:44, 17.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.03G/5.00G [00:43<03:17, 20.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.04G/5.00G [00:44<03:05, 21.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.05G/5.00G [00:44<02:52, 22.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.06G/5.00G [00:45<02:54, 22.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|▊   | 1.07G/5.00G [00:45<02:51, 22.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▊   | 1.08G/5.00G [00:46<02:59, 21.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▊   | 1.09G/5.00G [00:46<02:58, 21.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.10G/5.00G [00:46<02:36, 24.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.11G/5.00G [00:47<02:26, 26.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.12G/5.00G [00:47<02:50, 22.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.13G/5.00G [00:48<02:40, 24.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.14G/5.00G [00:48<02:43, 23.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.15G/5.00G [00:49<03:21, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.16G/5.00G [00:49<03:01, 21.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.17G/5.00G [00:50<02:51, 22.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.18G/5.00G [00:50<02:35, 24.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.20G/5.00G [00:50<02:24, 26.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.21G/5.00G [00:51<02:21, 26.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|▉   | 1.22G/5.00G [00:51<02:26, 25.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|▉   | 1.23G/5.00G [00:52<02:41, 23.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|▉   | 1.24G/5.00G [00:52<02:27, 25.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|▉   | 1.25G/5.00G [00:52<02:20, 26.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|█   | 1.26G/5.00G [00:53<02:18, 27.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|█   | 1.27G/5.00G [00:53<02:08, 29.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.28G/5.00G [00:53<02:06, 29.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.29G/5.00G [00:54<02:31, 24.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.30G/5.00G [00:54<02:22, 25.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.31G/5.00G [00:55<03:22, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|█   | 1.32G/5.00G [00:56<04:16, 14.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.33G/5.00G [00:59<06:39, 9.18MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.34G/5.00G [00:59<05:56, 10.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.35G/5.00G [01:00<05:00, 12.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.36G/5.00G [01:01<05:04, 11.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|█   | 1.37G/5.00G [01:01<04:28, 13.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█   | 1.38G/5.00G [01:02<03:51, 15.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█   | 1.39G/5.00G [01:02<03:19, 18.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█▏  | 1.41G/5.00G [01:04<04:48, 12.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|█▏  | 1.42G/5.00G [01:04<04:18, 13.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.43G/5.00G [01:04<03:34, 16.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.44G/5.00G [01:06<04:44, 12.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.45G/5.00G [01:06<03:51, 15.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.46G/5.00G [01:06<03:19, 17.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|█▏  | 1.47G/5.00G [01:07<03:35, 16.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.48G/5.00G [01:08<03:10, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.49G/5.00G [01:08<03:06, 18.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.50G/5.00G [01:08<02:49, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.51G/5.00G [01:09<03:14, 17.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|█▏  | 1.52G/5.00G [01:10<03:04, 18.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█▏  | 1.53G/5.00G [01:10<03:09, 18.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█▏  | 1.54G/5.00G [01:11<02:47, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█▏  | 1.55G/5.00G [01:11<03:07, 18.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█▎  | 1.56G/5.00G [01:12<02:59, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|█▎  | 1.57G/5.00G [01:12<02:38, 21.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.58G/5.00G [01:13<02:39, 21.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.59G/5.00G [01:13<02:42, 21.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.60G/5.00G [01:14<02:51, 19.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|█▎  | 1.61G/5.00G [01:14<02:38, 21.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|█▎  | 1.63G/5.00G [01:15<02:45, 20.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|█▎  | 1.64G/5.00G [01:15<02:52, 19.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|█▎  | 1.65G/5.00G [01:16<03:19, 16.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|█▎  | 1.66G/5.00G [01:17<02:53, 19.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|█▎  | 1.67G/5.00G [01:17<02:34, 21.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|█▎  | 1.68G/5.00G [01:18<03:03, 18.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|█▎  | 1.69G/5.00G [01:18<03:11, 17.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|█▎  | 1.70G/5.00G [01:19<03:16, 16.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|█▎  | 1.71G/5.00G [01:20<03:41, 14.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|█▍  | 1.72G/5.00G [01:20<03:00, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.73G/5.00G [01:21<02:38, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.74G/5.00G [01:21<02:42, 20.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.75G/5.00G [01:22<02:58, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.76G/5.00G [01:22<02:53, 18.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.77G/5.00G [01:23<02:36, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|█▍  | 1.78G/5.00G [01:23<02:16, 23.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|█▍  | 1.79G/5.00G [01:23<02:09, 24.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|█▍  | 1.80G/5.00G [01:24<01:58, 26.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|█▍  | 1.81G/5.00G [01:24<02:15, 23.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.82G/5.00G [01:25<02:07, 24.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.84G/5.00G [01:25<02:24, 21.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.85G/5.00G [01:26<02:13, 23.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.86G/5.00G [01:26<02:06, 24.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|█▍  | 1.87G/5.00G [01:26<01:57, 26.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.88G/5.00G [01:27<01:56, 26.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.89G/5.00G [01:27<01:56, 26.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.90G/5.00G [01:28<01:55, 26.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.91G/5.00G [01:28<02:04, 24.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|█▌  | 1.92G/5.00G [01:29<02:07, 24.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.93G/5.00G [01:29<01:55, 26.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.94G/5.00G [01:29<01:51, 27.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.95G/5.00G [01:30<01:53, 26.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.96G/5.00G [01:30<01:58, 25.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|█▌  | 1.97G/5.00G [01:30<01:56, 25.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█▌  | 1.98G/5.00G [01:31<01:50, 27.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█▌  | 1.99G/5.00G [01:31<01:51, 26.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█▌  | 2.00G/5.00G [01:32<01:50, 27.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|█▌  | 2.01G/5.00G [01:32<01:48, 27.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|█▌  | 2.02G/5.00G [01:32<02:01, 24.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|█▋  | 2.03G/5.00G [01:33<01:52, 26.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|█▋  | 2.04G/5.00G [01:33<02:00, 24.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|█▋  | 2.06G/5.00G [01:34<01:48, 27.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|█▋  | 2.07G/5.00G [01:34<01:42, 28.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.08G/5.00G [01:34<01:46, 27.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.09G/5.00G [01:36<02:59, 16.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.10G/5.00G [01:36<02:51, 16.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.11G/5.00G [01:36<02:25, 19.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.12G/5.00G [01:37<02:22, 20.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|█▋  | 2.13G/5.00G [01:37<02:21, 20.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|█▋  | 2.14G/5.00G [01:38<02:02, 23.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|█▋  | 2.15G/5.00G [01:38<01:49, 26.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|█▋  | 2.16G/5.00G [01:38<01:41, 28.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|█▋  | 2.17G/5.00G [01:39<01:39, 28.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|█▋  | 2.18G/5.00G [01:39<01:36, 29.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|█▊  | 2.19G/5.00G [01:39<01:32, 30.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|█▊  | 2.20G/5.00G [01:40<01:48, 25.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|█▊  | 2.21G/5.00G [01:40<01:51, 25.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|█▊  | 2.22G/5.00G [01:41<01:46, 26.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|█▊  | 2.23G/5.00G [01:41<01:44, 26.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|█▊  | 2.24G/5.00G [01:42<01:44, 26.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|█▊  | 2.25G/5.00G [01:42<01:41, 26.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|█▊  | 2.26G/5.00G [01:42<01:36, 28.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.28G/5.00G [01:43<01:54, 23.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.29G/5.00G [01:43<02:07, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.30G/5.00G [01:44<02:02, 22.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.31G/5.00G [01:45<02:36, 17.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.32G/5.00G [01:45<02:29, 18.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█▊  | 2.33G/5.00G [01:46<02:11, 20.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█▊  | 2.34G/5.00G [01:46<01:58, 22.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█▉  | 2.35G/5.00G [01:46<01:47, 24.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█▉  | 2.36G/5.00G [01:47<01:57, 22.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|█▉  | 2.37G/5.00G [01:48<02:09, 20.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.38G/5.00G [01:48<01:53, 23.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.39G/5.00G [01:48<01:41, 25.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.40G/5.00G [01:49<01:35, 27.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.41G/5.00G [01:49<01:35, 27.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.42G/5.00G [01:49<01:30, 28.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.43G/5.00G [01:50<01:24, 30.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.44G/5.00G [01:50<01:29, 28.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.45G/5.00G [01:50<01:29, 28.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.46G/5.00G [01:51<01:24, 29.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|█▉  | 2.47G/5.00G [01:51<01:36, 26.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|█▉  | 2.49G/5.00G [01:52<01:33, 26.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|█▉  | 2.50G/5.00G [01:52<01:39, 25.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██  | 2.51G/5.00G [01:53<01:46, 23.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|██  | 2.52G/5.00G [01:53<01:55, 21.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.53G/5.00G [01:54<02:03, 20.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.54G/5.00G [01:54<02:01, 20.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.55G/5.00G [01:55<02:19, 17.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.56G/5.00G [01:56<02:22, 17.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.57G/5.00G [01:56<02:18, 17.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.58G/5.00G [01:57<02:01, 19.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.59G/5.00G [01:57<02:17, 17.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.60G/5.00G [01:58<02:12, 18.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.61G/5.00G [01:58<01:57, 20.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.62G/5.00G [01:59<01:48, 21.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|██  | 2.63G/5.00G [01:59<01:37, 24.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|██  | 2.64G/5.00G [02:00<01:51, 21.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|██  | 2.65G/5.00G [02:00<01:50, 21.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|██▏ | 2.66G/5.00G [02:00<01:40, 23.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.67G/5.00G [02:01<01:49, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.68G/5.00G [02:02<02:01, 19.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.69G/5.00G [02:02<01:54, 20.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.71G/5.00G [02:03<01:45, 21.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.72G/5.00G [02:03<02:05, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.73G/5.00G [02:04<02:14, 16.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.74G/5.00G [02:05<02:33, 14.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.75G/5.00G [02:06<02:50, 13.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.76G/5.00G [02:06<02:26, 15.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.77G/5.00G [02:07<02:07, 17.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|██▏ | 2.78G/5.00G [02:08<02:43, 13.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|██▏ | 2.79G/5.00G [02:09<02:43, 13.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|██▏ | 2.80G/5.00G [02:09<02:27, 14.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|██▎ | 2.81G/5.00G [02:10<02:23, 15.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|██▎ | 2.82G/5.00G [02:10<01:57, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.83G/5.00G [02:11<01:38, 22.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.84G/5.00G [02:11<01:25, 25.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.85G/5.00G [02:11<01:39, 21.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.86G/5.00G [02:12<01:56, 18.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.87G/5.00G [02:13<01:51, 19.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.88G/5.00G [02:13<02:02, 17.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.89G/5.00G [02:14<01:57, 17.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.90G/5.00G [02:14<01:40, 20.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.92G/5.00G [02:15<01:56, 17.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██▎ | 2.93G/5.00G [02:16<02:11, 15.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██▎ | 2.94G/5.00G [02:16<01:50, 18.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██▎ | 2.95G/5.00G [02:17<01:38, 20.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██▎ | 2.96G/5.00G [02:17<01:26, 23.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|██▍ | 2.97G/5.00G [02:17<01:21, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 2.98G/5.00G [02:18<01:13, 27.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 2.99G/5.00G [02:18<01:10, 28.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 3.00G/5.00G [02:19<01:30, 21.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 3.01G/5.00G [02:19<01:32, 21.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 3.02G/5.00G [02:19<01:22, 23.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 3.03G/5.00G [02:20<01:16, 25.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 3.04G/5.00G [02:20<01:23, 23.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 3.05G/5.00G [02:21<01:17, 25.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 3.06G/5.00G [02:21<01:10, 27.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.07G/5.00G [02:21<01:08, 28.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.08G/5.00G [02:22<01:03, 30.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.09G/5.00G [02:22<01:01, 30.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.10G/5.00G [02:22<01:01, 31.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.11G/5.00G [02:23<01:07, 27.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|██▌ | 3.12G/5.00G [02:23<01:07, 27.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|██▌ | 3.14G/5.00G [02:23<01:03, 29.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|██▌ | 3.15G/5.00G [02:24<01:03, 29.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|██▌ | 3.16G/5.00G [02:24<00:59, 30.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|██▌ | 3.17G/5.00G [02:25<01:20, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.18G/5.00G [02:25<01:11, 25.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.19G/5.00G [02:26<01:51, 16.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.20G/5.00G [02:27<01:37, 18.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.21G/5.00G [02:27<01:28, 20.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.22G/5.00G [02:28<01:30, 19.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.23G/5.00G [02:29<01:47, 16.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.24G/5.00G [02:29<01:41, 17.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.25G/5.00G [02:30<02:00, 14.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.26G/5.00G [02:31<01:52, 15.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██▌ | 3.27G/5.00G [02:31<01:37, 17.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|██▋ | 3.28G/5.00G [02:31<01:23, 20.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|██▋ | 3.29G/5.00G [02:32<01:12, 23.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|██▋ | 3.30G/5.00G [02:32<01:08, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|██▋ | 3.31G/5.00G [02:33<01:24, 19.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██▋ | 3.32G/5.00G [02:33<01:28, 18.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██▋ | 3.33G/5.00G [02:34<01:32, 18.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██▋ | 3.34G/5.00G [02:35<01:26, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██▋ | 3.36G/5.00G [02:35<01:20, 20.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██▋ | 3.37G/5.00G [02:35<01:12, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.38G/5.00G [02:36<01:06, 24.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.39G/5.00G [02:36<01:12, 22.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.40G/5.00G [02:37<01:05, 24.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.41G/5.00G [02:37<00:59, 26.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.42G/5.00G [02:38<01:07, 23.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██▋ | 3.43G/5.00G [02:38<01:00, 25.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██▊ | 3.44G/5.00G [02:38<01:05, 23.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██▊ | 3.45G/5.00G [02:39<01:09, 22.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██▊ | 3.46G/5.00G [02:39<01:04, 23.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██▊ | 3.47G/5.00G [02:40<01:06, 22.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.48G/5.00G [02:40<01:11, 21.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.49G/5.00G [02:41<01:18, 19.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.50G/5.00G [02:42<01:18, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|██▊ | 3.51G/5.00G [02:42<01:17, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|██▊ | 3.52G/5.00G [02:43<01:16, 19.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|██▊ | 3.53G/5.00G [02:43<01:07, 21.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|██▊ | 3.54G/5.00G [02:44<01:12, 20.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|██▊ | 3.55G/5.00G [02:44<01:20, 17.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|██▊ | 3.57G/5.00G [02:45<01:16, 18.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|██▊ | 3.58G/5.00G [02:45<01:16, 18.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|██▊ | 3.59G/5.00G [02:46<01:06, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|██▉ | 3.60G/5.00G [02:46<00:58, 23.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|██▉ | 3.61G/5.00G [02:46<00:56, 24.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|██▉ | 3.62G/5.00G [02:47<01:01, 22.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.63G/5.00G [02:47<00:55, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.64G/5.00G [02:48<00:50, 26.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.65G/5.00G [02:48<00:49, 27.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.66G/5.00G [02:49<01:14, 18.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|██▉ | 3.67G/5.00G [02:49<01:05, 20.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|██▉ | 3.68G/5.00G [02:50<01:15, 17.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|██▉ | 3.69G/5.00G [02:51<01:16, 17.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|██▉ | 3.70G/5.00G [02:52<01:23, 15.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|██▉ | 3.71G/5.00G [02:52<01:17, 16.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|██▉ | 3.72G/5.00G [02:53<01:28, 14.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|██▉ | 3.73G/5.00G [02:54<01:15, 16.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|██▉ | 3.74G/5.00G [02:54<01:13, 17.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|███ | 3.75G/5.00G [02:55<01:03, 19.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|███ | 3.76G/5.00G [02:55<01:15, 16.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███ | 3.77G/5.00G [02:56<01:17, 15.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███ | 3.79G/5.00G [02:57<01:08, 17.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███ | 3.80G/5.00G [02:57<01:07, 17.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███ | 3.81G/5.00G [02:58<01:01, 19.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███ | 3.82G/5.00G [02:58<00:57, 20.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|███ | 3.83G/5.00G [02:58<00:51, 22.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|███ | 3.84G/5.00G [02:59<00:49, 23.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|███ | 3.85G/5.00G [02:59<00:49, 23.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|███ | 3.86G/5.00G [03:00<00:46, 24.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|███ | 3.87G/5.00G [03:00<00:43, 25.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███ | 3.88G/5.00G [03:01<00:54, 20.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███ | 3.89G/5.00G [03:01<00:48, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███ | 3.90G/5.00G [03:02<00:59, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███▏| 3.91G/5.00G [03:02<00:52, 20.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.92G/5.00G [03:03<00:47, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.93G/5.00G [03:03<00:51, 20.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.94G/5.00G [03:04<00:50, 20.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.95G/5.00G [03:04<00:44, 23.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.96G/5.00G [03:04<00:41, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 3.97G/5.00G [03:05<00:51, 19.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 3.98G/5.00G [03:06<00:45, 22.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 4.00G/5.00G [03:06<00:40, 24.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 4.01G/5.00G [03:07<00:49, 20.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 4.02G/5.00G [03:07<00:54, 17.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|███▏| 4.03G/5.00G [03:08<00:45, 21.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|███▏| 4.04G/5.00G [03:08<00:40, 23.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|███▏| 4.05G/5.00G [03:08<00:37, 25.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|███▏| 4.06G/5.00G [03:09<00:40, 22.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|███▎| 4.07G/5.00G [03:09<00:37, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|███▎| 4.08G/5.00G [03:09<00:33, 27.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|███▎| 4.09G/5.00G [03:10<00:31, 28.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|███▎| 4.10G/5.00G [03:10<00:36, 24.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|███▎| 4.11G/5.00G [03:11<00:33, 26.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|███▎| 4.12G/5.00G [03:11<00:31, 28.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|███▎| 4.13G/5.00G [03:11<00:30, 28.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|███▎| 4.14G/5.00G [03:12<00:35, 23.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|███▎| 4.15G/5.00G [03:12<00:34, 24.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|███▎| 4.16G/5.00G [03:13<00:32, 25.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|███▎| 4.17G/5.00G [03:13<00:31, 26.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|███▎| 4.18G/5.00G [03:14<00:38, 21.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|███▎| 4.19G/5.00G [03:14<00:33, 24.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|███▎| 4.20G/5.00G [03:15<00:31, 25.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|███▍| 4.22G/5.00G [03:15<00:37, 21.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|███▍| 4.23G/5.00G [03:16<00:34, 22.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|███▍| 4.24G/5.00G [03:17<00:46, 16.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|███▍| 4.25G/5.00G [03:17<00:44, 16.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|███▍| 4.26G/5.00G [03:18<00:47, 15.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|███▍| 4.27G/5.00G [03:19<00:43, 16.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|███▍| 4.28G/5.00G [03:19<00:46, 15.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|███▍| 4.29G/5.00G [03:20<00:43, 16.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|███▍| 4.30G/5.00G [03:21<00:43, 15.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|███▍| 4.31G/5.00G [03:21<00:36, 18.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|███▍| 4.32G/5.00G [03:21<00:30, 21.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███▍| 4.33G/5.00G [03:23<00:46, 14.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███▍| 4.34G/5.00G [03:23<00:43, 15.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███▍| 4.35G/5.00G [03:24<00:40, 16.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|███▍| 4.36G/5.00G [03:24<00:38, 16.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███▌| 4.37G/5.00G [03:25<00:44, 14.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███▌| 4.38G/5.00G [03:27<01:05, 9.31MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███▌| 4.39G/5.00G [03:28<00:51, 11.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███▌| 4.40G/5.00G [03:28<00:42, 14.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|███▌| 4.41G/5.00G [03:29<00:42, 13.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|███▌| 4.42G/5.00G [03:29<00:38, 15.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|███▌| 4.44G/5.00G [03:30<00:32, 17.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|███▌| 4.45G/5.00G [03:30<00:31, 17.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|███▌| 4.46G/5.00G [03:31<00:29, 18.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|███▌| 4.47G/5.00G [03:31<00:28, 18.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|███▌| 4.48G/5.00G [03:32<00:30, 17.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|███▌| 4.49G/5.00G [03:33<00:32, 15.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|███▌| 4.50G/5.00G [03:34<00:35, 13.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|███▌| 4.51G/5.00G [03:34<00:32, 15.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|███▌| 4.52G/5.00G [03:35<00:30, 15.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|███▋| 4.53G/5.00G [03:36<00:30, 15.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|███▋| 4.54G/5.00G [03:36<00:28, 16.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|███▋| 4.55G/5.00G [03:38<00:43, 10.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|███▋| 4.56G/5.00G [03:39<00:37, 11.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.57G/5.00G [03:40<00:39, 10.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.58G/5.00G [03:41<00:34, 12.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.59G/5.00G [03:41<00:29, 13.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.60G/5.00G [03:42<00:26, 14.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|███▋| 4.61G/5.00G [03:43<00:26, 14.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|███▋| 4.62G/5.00G [03:43<00:21, 17.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|███▋| 4.63G/5.00G [03:43<00:18, 20.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|███▋| 4.65G/5.00G [03:44<00:15, 22.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|███▋| 4.66G/5.00G [03:44<00:13, 24.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|███▋| 4.67G/5.00G [03:44<00:12, 25.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|███▋| 4.68G/5.00G [03:45<00:18, 17.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|███▊| 4.69G/5.00G [03:46<00:16, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|███▊| 4.70G/5.00G [03:46<00:16, 18.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|███▊| 4.71G/5.00G [03:47<00:15, 18.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|███▊| 4.72G/5.00G [03:47<00:13, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.73G/5.00G [03:48<00:11, 23.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.74G/5.00G [03:48<00:10, 24.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.75G/5.00G [03:49<00:13, 17.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|███▊| 4.76G/5.00G [03:50<00:14, 15.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███▊| 4.77G/5.00G [03:50<00:12, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███▊| 4.78G/5.00G [03:51<00:11, 18.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███▊| 4.79G/5.00G [03:52<00:13, 15.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███▊| 4.80G/5.00G [03:52<00:12, 15.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|███▊| 4.81G/5.00G [03:53<00:10, 18.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███▊| 4.82G/5.00G [03:53<00:09, 18.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███▊| 4.83G/5.00G [03:54<00:09, 17.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███▉| 4.84G/5.00G [03:54<00:07, 19.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███▉| 4.85G/5.00G [03:55<00:06, 21.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|███▉| 4.87G/5.00G [03:55<00:05, 24.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███▉| 4.88G/5.00G [03:56<00:06, 18.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███▉| 4.89G/5.00G [03:56<00:05, 18.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███▉| 4.90G/5.00G [03:57<00:04, 20.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███▉| 4.91G/5.00G [03:57<00:04, 22.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|███▉| 4.92G/5.00G [03:58<00:03, 23.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.93G/5.00G [03:58<00:02, 25.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.94G/5.00G [03:58<00:02, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.95G/5.00G [03:59<00:02, 20.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.96G/5.00G [03:59<00:01, 22.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.97G/5.00G [04:00<00:01, 23.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|███▉| 4.98G/5.00G [04:00<00:00, 22.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|███▉| 4.99G/5.00G [04:01<00:00, 22.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|████| 5.00G/5.00G [04:01<00:00, 20.7MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████            | 1/2 [04:02<04:02, 242.75s/it]\n",
      "model-00002-of-00002.safetensors:   0%|              | 0.00/564M [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   2%|     | 10.5M/564M [00:00<00:29, 18.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   4%|▏    | 21.0M/564M [00:00<00:24, 22.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6%|▎    | 31.5M/564M [00:01<00:23, 22.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7%|▎    | 41.9M/564M [00:01<00:24, 21.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9%|▍    | 52.4M/564M [00:02<00:24, 20.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11%|▌    | 62.9M/564M [00:02<00:22, 22.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13%|▋    | 73.4M/564M [00:03<00:19, 25.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15%|▋    | 83.9M/564M [00:03<00:17, 27.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17%|▊    | 94.4M/564M [00:03<00:16, 27.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19%|█     | 105M/564M [00:04<00:19, 23.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20%|█▏    | 115M/564M [00:04<00:19, 22.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22%|█▎    | 126M/564M [00:05<00:20, 21.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24%|█▍    | 136M/564M [00:06<00:20, 20.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26%|█▌    | 147M/564M [00:06<00:18, 23.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28%|█▋    | 157M/564M [00:06<00:16, 24.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30%|█▊    | 168M/564M [00:07<00:15, 26.3MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32%|█▉    | 178M/564M [00:07<00:13, 28.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33%|██    | 189M/564M [00:07<00:12, 30.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35%|██    | 199M/564M [00:08<00:12, 28.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37%|██▏   | 210M/564M [00:08<00:14, 23.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39%|██▎   | 220M/564M [00:09<00:13, 25.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41%|██▍   | 231M/564M [00:09<00:12, 26.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43%|██▌   | 241M/564M [00:09<00:12, 26.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  45%|██▋   | 252M/564M [00:10<00:13, 23.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46%|██▊   | 262M/564M [00:11<00:14, 20.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  48%|██▉   | 273M/564M [00:11<00:15, 19.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50%|███   | 283M/564M [00:12<00:13, 21.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52%|███   | 294M/564M [00:12<00:13, 19.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  54%|███▏  | 304M/564M [00:13<00:11, 22.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56%|███▎  | 315M/564M [00:13<00:13, 19.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58%|███▍  | 325M/564M [00:14<00:11, 20.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60%|███▌  | 336M/564M [00:14<00:10, 22.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61%|███▋  | 346M/564M [00:14<00:08, 24.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63%|███▊  | 357M/564M [00:15<00:07, 26.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65%|███▉  | 367M/564M [00:15<00:06, 28.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67%|████  | 377M/564M [00:15<00:06, 27.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69%|████▏ | 388M/564M [00:16<00:06, 28.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71%|████▏ | 398M/564M [00:16<00:05, 27.8MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73%|████▎ | 409M/564M [00:17<00:07, 20.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  74%|████▍ | 419M/564M [00:17<00:06, 21.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76%|████▌ | 430M/564M [00:18<00:06, 19.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78%|████▋ | 440M/564M [00:19<00:06, 19.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80%|████▊ | 451M/564M [00:20<00:07, 16.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82%|████▉ | 461M/564M [00:20<00:06, 16.3MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84%|█████ | 472M/564M [00:21<00:05, 17.8MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86%|█████▏| 482M/564M [00:21<00:03, 20.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87%|█████▏| 493M/564M [00:21<00:03, 22.8MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89%|█████▎| 503M/564M [00:22<00:02, 21.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91%|█████▍| 514M/564M [00:22<00:02, 24.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93%|█████▌| 524M/564M [00:22<00:01, 26.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  95%|█████▋| 535M/564M [00:23<00:01, 24.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97%|█████▊| 545M/564M [00:23<00:00, 25.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99%|█████▉| 556M/564M [00:24<00:00, 26.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|██████| 564M/564M [00:24<00:00, 22.9MB/s]\u001b[A\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [04:28<00:00, 134.16s/it]\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [04:28<00:00, 134.16s/it]\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [04:28<00:00, 134.17s/it]\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [04:28<00:00, 134.19s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.37s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.14.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.23.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.11.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "generation_config.json: 100%|███████████████████| 124/124 [00:00<00:00, 482kB/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.63s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.29.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.24.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.66s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.8.self_attn.v_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.weight']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.14.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.45s/it]\n",
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.13.self_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.5.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.23.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[2024-02-28 03:39:36,169] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "tokenizer_config.json: 100%|███████████████| 7.34k/7.34k [00:00<00:00, 22.7MB/s]\n",
      "[2024-02-28 03:39:37,269] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-28 03:39:37,318] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-02-28 03:39:37,582] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "vocab.json: 100%|█████████████████████████████| 798k/798k [00:01<00:00, 758kB/s]\n",
      "merges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 1.74MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 2.11M/2.11M [00:01<00:00, 1.57MB/s]\n",
      "added_tokens.json: 100%|███████████████████| 1.08k/1.08k [00:00<00:00, 4.73MB/s]\n",
      "special_tokens_map.json: 100%|████████████████| 99.0/99.0 [00:00<00:00, 468kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:03:39:42,742 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:03:39:42,755 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:03:39:42,774 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-02-28:03:39:42,787 INFO     [huggingface.py:322] Using 4 devices with data parallelism\n",
      "2024-02-28:03:39:42,787 INFO     [evaluator.py:150] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n",
      "2024-02-28:03:39:54,212 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:03:39:54,213 INFO     [task.py:361] Building contexts for gsm8k on rank 1...\n",
      "2024-02-28:03:39:54,253 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:03:39:54,253 INFO     [task.py:361] Building contexts for gsm8k on rank 2...\n",
      "2024-02-28:03:39:54,488 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:03:39:54,489 INFO     [task.py:361] Building contexts for gsm8k on rank 0...\n",
      "2024-02-28:03:39:54,591 WARNING  [evaluator.py:182] Overwriting default num_fewshot of gsm8k from 5 to 5\n",
      "2024-02-28:03:39:54,592 INFO     [task.py:361] Building contexts for gsm8k on rank 3...\n",
      "2024-02-28:03:39:58,510 INFO     [evaluator.py:369] Running generate_until requests\n",
      "2024-02-28:03:39:58,511 INFO     [evaluator.py:369] Running generate_until requests\n",
      "2024-02-28:03:39:58,511 INFO     [evaluator.py:369] Running generate_until requests\n",
      "  0%|                                                   | 0/330 [00:00<?, ?it/s]2024-02-28:03:39:58,520 INFO     [evaluator.py:369] Running generate_until requests\n",
      "100%|█████████████████████████████████████████| 330/330 [57:41<00:00, 10.49s/it]\n",
      "hf (pretrained=microsoft/phi-2), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n",
      "|Tasks|Version|     Filter     |n-shot|  Metric   |Value|   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|----:|---|-----:|\n",
      "|gsm8k|      3|strict-match    |     5|exact_match|    0|±  |     0|\n",
      "|     |       |flexible-extract|     5|exact_match|    0|±  |     0|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch -m lm_eval --model hf \\\n",
    "    --model_args pretrained=microsoft/phi-2 \\\n",
    "    --tasks gsm8k \\\n",
    "    --batch_size 1 \\\n",
    "    --num_fewshot 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
